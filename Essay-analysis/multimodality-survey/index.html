<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"rj-gu.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="以下是对一部分多模态相关论文的模型分析，包括ViT、CLIP、Swin Transformer、VLMo、BLIP、LLaVa。">
<meta property="og:type" content="article">
<meta property="og:title" content="多模态有关论文模型介绍分析">
<meta property="og:url" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/index.html">
<meta property="og:site_name" content="Rongjian Gu&#39;s Homepage">
<meta property="og:description" content="以下是对一部分多模态相关论文的模型分析，包括ViT、CLIP、Swin Transformer、VLMo、BLIP、LLaVa。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710103323153.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710104757859.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710111308736.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710114049122.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710114027734.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710144932751.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710153012398.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710160707171.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710174920050.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710193309555.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710194140782.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710210918306.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710210617787.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710211657315.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240711145255124.png">
<meta property="og:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240711174441702.png">
<meta property="article:published_time" content="2024-07-10T02:29:44.000Z">
<meta property="article:modified_time" content="2024-07-11T12:00:09.667Z">
<meta property="article:author" content="RJ-Gu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://rj-gu.github.io/Essay-analysis/multimodality-survey/image-20240710103323153.png">

<link rel="canonical" href="https://rj-gu.github.io/Essay-analysis/multimodality-survey/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  
  
    <script src="/js/cursor/love.min.js"></script>
  


  <title>多模态有关论文模型介绍分析 | Rongjian Gu's Homepage</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Rongjian Gu's Homepage</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Simple thoughts; Simple works.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/RJ-Gu" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://rj-gu.github.io/Essay-analysis/multimodality-survey/">
    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="RJ-Gu">
      <meta itemprop="description" content="A subtle homepage of an ordinary student in USTC">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Rongjian Gu's Homepage">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          多模态有关论文模型介绍分析
        </h1>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2024-07-10 10:29:44" itemprop="dateCreated datePublished" datetime="2024-07-10T10:29:44+08:00">2024-07-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-07-11 20:00:09" itemprop="dateModified" datetime="2024-07-11T20:00:09+08:00">2024-07-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Essay-analysis/" itemprop="url" rel="index"><span itemprop="name">Essay analysis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>以下是对一部分多模态相关论文的模型分析，包括ViT、CLIP、Swin Transformer、VLMo、BLIP、LLaVa。</p>
<span id="more"></span>

<h2 id="ViT"><a href="#ViT" class="headerlink" title="ViT"></a>ViT</h2><p><img src="/Essay-analysis/multimodality-survey/image-20240710103323153.png" alt="image-20240710103323153"></p>
<p>ViT的motivation是将Transformer应用到CV领域。这个想法的难点在于如何将NLP中token的embedding对应到图像中。</p>
<p>ViT对这个问题的解决方案是将图像划分为patches，例如将一张224x224x3的图像按长宽进行划分；假设每个patch的大小为14x14x3，则可以分成(224&#x2F;14)^2&#x3D;256个patch，并横向排成一个sequence，作为Transformer的输入。</p>
<p>上述操作可以得到图像的embedding，但存在的问题是：attention机制计算patches之间的attention score时，没有patches之间位置的信息。attention机制对所有图像块两两计算分数，因此两个patch交换顺序后仍然可以计算。因此，需要增加patch在图像中位置的编码。例如图像被分为9个patches，则给这9个patch编号1-9，并进行embedding，加到patch的embedding中，作为encoder的输入。</p>
<p>除此之外，为了匹配NLP任务中存在的[CLS]符号，在embedding输入encoder之前，还需要在最开始增加编号0的[CLS]embedding。</p>
<h2 id="CLIP"><a href="#CLIP" class="headerlink" title="CLIP"></a>CLIP</h2><p><img src="/Essay-analysis/multimodality-survey/image-20240710104757859.png" alt="image-20240710104757859"></p>
<p>CLIP的motivation是使用Transformer做图文匹配。为此，他需要大量的图片文本对作为训练集。</p>
<p>CLIP的结构是将文本通过text encoder转换为embedding，将图片通过image encoder转换为embedding，最后计算这些embedding的相似度。</p>
<p>对于N个图片文本对，图片和文本的embedding可以构成两个张量：文本张量中$T_1,…,T_N$表示文本embedding，图片张量中$I_1,…,I_N$表示图片embedding。这两个张量中的embedding两两做内积，可以得到一个矩阵，表示相似度。</p>
<p>在这个相似度矩阵中，最理想的结果是对角线上元素为1，其他地方元素为0.计算交叉熵损失就可以得到差距，进而训练模型。</p>
<h2 id="Swin-Transformer"><a href="#Swin-Transformer" class="headerlink" title="Swin Transformer"></a>Swin Transformer</h2><p><img src="/Essay-analysis/multimodality-survey/image-20240710111308736.png" alt="image-20240710111308736"></p>
<p>Swin Transformer的motivation是在ViT的基础上增强跨窗口能力。这可以通过移动窗口机制实现。</p>
<ul>
<li>Swin Transformer首先将图片划分为4x4的patch，将$H\times W\times 3$的图片划分为$\frac H 4\times\frac W 4\times (3\times 4\times 4)&#x3D;48$的张量；</li>
<li>C为超参数，上述张量通过线性映射到$\frac H 4\times\frac W 4\times C$的维度上；</li>
<li>Swin Transformer Block不改变维度，进入第二个Block维度仍然为$\frac H 4\times\frac W 4\times C$；</li>
<li>Patch Merging操作例：原来4*4矩阵，从上到下从左到右分别为1-16。现在将1 3 9 11合并为2*2矩阵，2 4 10 12合并，类似得到4个2*2矩阵<br>在channel上拼接（池化），得到$\frac H 2\times \frac W 2\times 4C$的张量，在经过1*1卷积将4C降为2C</li>
</ul>
<p>移动窗口多头自注意力：</p>
<p><img src="/Essay-analysis/multimodality-survey/image-20240710114049122.png" alt="image-20240710114049122"></p>
<p><img src="/Essay-analysis/multimodality-survey/image-20240710114027734.png" alt="image-20240710114027734"></p>
<p>每次移动原窗口的一半，使得不同窗口之间可以进行信息交互。但移动窗口后，4个窗口会变成9个窗口，增加计算量。可以使用循环移位方法维持4个窗口不变，但增加掩码防止原本不相邻的位置计算注意力分数。</p>
<h2 id="MoCo"><a href="#MoCo" class="headerlink" title="MoCo"></a>MoCo</h2><p><img src="/Essay-analysis/multimodality-survey/image-20240710144932751.png" alt="image-20240710144932751"></p>
<p>MoCo的motivation是使用对比学习的方式做自监督学习。对比学习可以理解为检索字典的任务，根据query的embedding在字典中查找正样本的key对应的embedding，这两个embedding应该相似；与负样本的key对应的embedding应该不相似。</p>
<p>对比学习中，字典大小决定了训练效果；字典应该越大越好。但字典过大会导致每次更新权重的计算量增加，很可能无法训练。为解决该问题，文章引入了队列，每次从队列中抽取一部分key计算相似度，更新encoder权重后计算embedding加入队列尾，从队列头取出元素计算loss。</p>
<p>但这样会引入另一个问题：队列中每个元素的embedding都是由不同状态的encoder计算得到的，这会导致不一致性。为解决该问题，文章引入了动量机制（momentum）更新权重；即：每次对于key更新权重都保留大量原始信息，只做很小的调整。即：<br>$$<br>\theta_k \leftarrow m\theta_k+(1-m)\theta_q<br>$$<br>其中$m$取值常为0.99。这样就保证了query encoder更新时，key encoder更新更缓慢，保持了队列元素的一致性。</p>
<h2 id="DETR"><a href="#DETR" class="headerlink" title="DETR"></a>DETR</h2><p><img src="/Essay-analysis/multimodality-survey/image-20240710153012398.png" alt="image-20240710153012398"></p>
<p>DETR的motivation是用Transformer做目标检测。在DETR之前的目标检测模型大多使用了非极大值抑制（non-maximum supression, nms）过程，导致模型复杂，超参数难调节。这篇文章没有使用nms过程，但仍然达到了较好的效果。</p>
<p>对于一张图片，DETR先生成N个框，再使用二分图匹配的匈牙利算法找到匹配最好的几个框，从而计算loss。具体而言，DETR的backbone模型是CNN（ResNet），抽取出图片特征后增加positional encoding，输入transformer encoder+decoder+FFN中生成预测的N个框，包括位置以及类别。在decoder阶段，transformer的输入是object queries，是可学习参数，用来引导生成目标框。</p>
<h2 id="ALBEF"><a href="#ALBEF" class="headerlink" title="ALBEF"></a>ALBEF</h2><p><img src="/Essay-analysis/multimodality-survey/image-20240710160707171.png" alt="image-20240710160707171"></p>
<p>ALBEF是另一种学习图片与文本对齐的模型，与CLIP目的一致。</p>
<p>一般而言，图像比文本包含更多的信息，需要更深的网络提取特征。因此为了保持模型的规模与之前的模型可比，文章将文本encoder分为两部分，只用6层attention block作为text encoder，而图像的encoder仍然保持12层。</p>
<p>在12层的image encoder和6层的text encoder后，输入文本图像对的特征就已经被抽取出来了。每个文本图像对计算loss，就可以得到ITC loss。这个loss是在fusion之前计算的，即没有经过最后多模态encoder的计算就可以得到，因此这个loss就让image和text在fusion之前就进行了align，即标题。</p>
<p>ITM loss是经过fusion之后，在模型最后增加FC层，判断图像和文本是否在一个类这样一个二分类任物的loss。但实际上这个loss过于简单，因为负样本数量远远大于正样本，直接输出不属于一个类别准确率也很高。因此可以通过ITC loss得到最接近正样本的负样本（hard negatives），将这个负样本作为计算loss的根据，使得这个loss更加challenging。</p>
<p>MLM loss即BERT中对语句进行MASK操作后判断MASK掉的单词，从而计算loss。这次输入的text是被MASK的语句，但其他两个loss都是原始text，因此需要两次forward过程。</p>
<p>Momentum Distillation：因为数据noise很大，可能生成的负样本描述对图片也是一个很好的描述。因此需要构建一个momentum model，使用这个模型生成pseudo targets，使得one hot label变为multi-hot label。这样在训练时，如果原始label是错误的，或是noisy的时候，momentum label也可以提供帮助。这两个模型生成两个loss，通过momentum方式影响最终loss即可。</p>
<h2 id="VLMo"><a href="#VLMo" class="headerlink" title="VLMo"></a>VLMo</h2><p><img src="/Essay-analysis/multimodality-survey/image-20240710174920050.png" alt="image-20240710174920050"></p>
<p>VLMo的motivation是发现：</p>
<ul>
<li>以CLIP为首的双塔（dual-encoder）架构因为计算模态间交互只使用了矩阵乘法，在检索上很高效；但这种简单的交互面对复杂的情况难以建模；</li>
<li>单塔架构：仅对文本和图像进行相对简单的预处理得到embedding，在模态间交互时使用encoder进行建模。这种方式建模能力强，但推理慢（因为要通过encoder）。</li>
</ul>
<p>因此将这两种结构进行结合，根据不同情景调用不同expert即可。（共享参数）</p>
<h2 id="BLIP"><a href="#BLIP" class="headerlink" title="BLIP"></a>BLIP</h2><p><img src="/Essay-analysis/multimodality-survey/image-20240710193309555.png" alt="image-20240710193309555"></p>
<p>BLIP的motivation有两个角度：</p>
<ul>
<li>模型角度：encoder only的模型可以进行图像文本retrieval，但不能直接用来进行文本生成（例如图像生成字幕）；encoder+decoder的模型可以进行文本生成，但还未用到图像文本retrieval。如果使用一个模型将这些功能进行unify，将会提升功能。</li>
<li>数据角度：无论脏数据集的大小，其都会在一定程度上影响训练结果。</li>
</ul>
<p>因此BLIP提出：可以在不同的应用上使用不同的模型，共享部分参数。结合了ALBEF和VLMo的特点。</p>
<p>图像仍然使用标准ViT模型，针对文本有3个不同encoder&#x2F;decoder，包括：</p>
<ul>
<li>对文本的text encoder，生成text embedding，可以用来和图像的embedding计算itc分数；</li>
<li>加上了图像信息的image-grounded text encoder，可以直接用来生成图文匹配结果（二分类）；</li>
<li>类似GPT的生成模型image-grounded text decoder，可以借助图像和（初始）文本信息，生成符合图像信息的文本。</li>
</ul>
<p>这三个文本模型中，前两个模型的self attention模块共享权重；后两个模型的cross attention模块共享权重；三个模型的feed forward模块共享权重。</p>
<p><img src="/Essay-analysis/multimodality-survey/image-20240710194140782.png" alt="image-20240710194140782"></p>
<p><strong>Captioning and Filtering</strong>：已知目前有大量的noisy数据集，该方法提供了一种消除噪音训练的方法。noisy数据集为${(I_w,T_w)}$图像文本对，其中$T_w$不可信；人工标注数据集为${(I_h,T_h)}$图像文本对，其中$T_h$可信。</p>
<ul>
<li>首先使用这两种数据集训练，得到一个初步可用的网络；</li>
<li>将其中的image-grounded text encoder（即第一张图的第二个text模型）提出，作为filter；将image-grounded text-decoder（即第一张图的第三个text模型）作为captioner；</li>
<li>对于noisy数据集中的所有$(I_w,T_w)$数据对，都做以下操作：<ul>
<li>使用filter对$(I_w,T_w)$做检验，如果不通过filter就删除；</li>
<li>使用captioner对$I_w$生成caption，成为新的$(I_w,T_w)$数据对，再经过filter检验；</li>
<li>只有通过filter的数据对才能保留。</li>
</ul>
</li>
<li>通过上述方式，留下的数据对包括：<ul>
<li>通过了检验的noisy数据集原始数据对$(I_w,T_w)$；</li>
<li>通过了检验的noisy数据集图片和captioner生成的caption数据对$(I_w,T_s)$；</li>
<li>人工标注的数据集原始数据对$(I_h,T_h)$。</li>
</ul>
</li>
<li>留下的数据对质量更高，可以用来重新训练模型。</li>
</ul>
<h2 id="BLIP2"><a href="#BLIP2" class="headerlink" title="BLIP2"></a>BLIP2</h2><p><img src="/Essay-analysis/multimodality-survey/image-20240710210918306.png" alt="image-20240710210918306"></p>
<p><img src="/Essay-analysis/multimodality-survey/image-20240710210617787.png" alt="image-20240710210617787"></p>
<p>BLIP2的motivation是使用LLM作为模型的一部分时，如果冻结LLM参数，只训练其他部分，训练效率应该会提高。</p>
<p>不更新LLM参数代表着第一张图中image encoder和LLM冻结，但直接连接二者会导致特征空间不匹配，因此需要增加一个适配层，即Querying Transformer。训练Q-Former的过程仍然使用ITM等loss。</p>
<p><img src="/Essay-analysis/multimodality-survey/image-20240710211657315.png" alt="image-20240710211657315"></p>
<p>在生成任务中，因为Q-Former已经提取了图像的特征并转化为了语言模型的表达形式，因此通过一个全连接层就可以直接输入到预训练的encoder&#x2F;decoder中，用于生成描述。生成描述既可以通过直接将embedding注入decoder来生成，也可以通过将embedding和实际文本的embedding结合，通过encoder+decoder结构来生成。</p>
<h2 id="LLaVA-LLaVA-1-5"><a href="#LLaVA-LLaVA-1-5" class="headerlink" title="LLaVA&#x2F;LLaVA-1.5"></a>LLaVA&#x2F;LLaVA-1.5</h2><p><img src="/Essay-analysis/multimodality-survey/image-20240711145255124.png" alt="image-20240711145255124"></p>
<p>LLaVA关注点在于将image信息与LLM的文本输入信息对齐。图像在通过vision encoder得到其hidden state后，通过一个projection layer将其转化为text的hidden state，进而将image和text信息进行统一。</p>
<p>在文本处理中，如果涉及到图像信息，则将文本中的&lt;image&gt; token替换为图像的embedding即可。</p>
<p><img src="/Essay-analysis/multimodality-survey/image-20240711174441702.png" alt="image-20240711174441702"></p>
<p>LLaVA-1.5使用了多种优化方式，例如更换更大的LLM、增加分辨率等，实现了更高的准确率。</p>

    </div>

    
    
    

    
      <div style="text-align:center;color: #ccc;font-size:14px;">------------- Thanks for watching <i class="fa fa-heart"></i> -------------</div>

    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/LLM-application/LLM-personalization-survey/" rel="prev" title="LLM与个性化技术相关调研">
      <i class="fa fa-chevron-left"></i> LLM与个性化技术相关调研
    </a></div>
      <div class="post-nav-item">
    <a href="/Essay-analysis/multimodal-doc-comprehension/" rel="next" title="多模态文字处理有关模型介绍分析">
      多模态文字处理有关模型介绍分析 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#ViT"><span class="nav-text">ViT</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CLIP"><span class="nav-text">CLIP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Swin-Transformer"><span class="nav-text">Swin Transformer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MoCo"><span class="nav-text">MoCo</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DETR"><span class="nav-text">DETR</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ALBEF"><span class="nav-text">ALBEF</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VLMo"><span class="nav-text">VLMo</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BLIP"><span class="nav-text">BLIP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BLIP2"><span class="nav-text">BLIP2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LLaVA-LLaVA-1-5"><span class="nav-text">LLaVA&#x2F;LLaVA-1.5</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="RJ-Gu"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">RJ-Gu</p>
  <div class="site-description" itemprop="description">A subtle homepage of an ordinary student in USTC</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/RJ-Gu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;RJ-Gu" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:gurongjian@mail.ustc.edu.cn" title="E-Mail → mailto:gurongjian@mail.ustc.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">RJ-Gu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest-nomobile.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
